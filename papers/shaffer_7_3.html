

<html> 
<head><script src="//archive.org/includes/analytics.js?v=cf34f82" type="text/javascript"></script>
<script type="text/javascript">window.addEventListener('DOMContentLoaded',function(){var v=archive_analytics.values;v.service='wb';v.server_name='wwwb-app214.us.archive.org';v.server_ms=244;archive_analytics.send_pageview({});});</script>
<script type="text/javascript" src="/_static/js/bundle-playback.js?v=UfTkgsKx" charset="utf-8"></script>
<script type="text/javascript" src="/_static/js/wombat.js?v=UHAOicsW" charset="utf-8"></script>
<script type="text/javascript">
  __wm.init("https://web.archive.org/web");
  __wm.wombat("http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm","20130307064041","https://web.archive.org/","web","/_static/",
	      "1362638441");
</script>
<link rel="stylesheet" type="text/css" href="/_static/css/banner-styles.css?v=omkqRugM" />
<link rel="stylesheet" type="text/css" href="/_static/css/iconochive.css?v=qtvMKcIJ" />
<!-- End Wayback Rewrite JS Include -->
<title>Journal of Statistics Education, V7N3: Shaffer</title></head>  
<body bgcolor="#ffffff"><!-- BEGIN WAYBACK TOOLBAR INSERT -->
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  /*min-width:800px !important;*/
}
</style>
<script>__wm.rw(0);</script>
<div id="wm-ipp-base" lang="en" style="display:none;direction:ltr;">
<div id="wm-ipp" style="position:fixed;left:0;top:0;right:0;">
<div id="wm-ipp-inside">
  <div style="position:relative;">
    <div id="wm-logo" style="float:left;width:110px;padding-top:12px;">
      <a href="/web/" title="Wayback Machine home page"><img src="/_static/images/toolbar/wayback-toolbar-logo-200.png" srcset="/_static/images/toolbar/wayback-toolbar-logo-100.png, /_static/images/toolbar/wayback-toolbar-logo-150.png 1.5x, /_static/images/toolbar/wayback-toolbar-logo-200.png 2x" alt="Wayback Machine" style="width:100px" border="0" /></a>
    </div>
    <div class="r" style="float:right;">
      <div id="wm-btns" style="text-align:right;height:25px;">
                  <div id="wm-save-snapshot-success">success</div>
          <div id="wm-save-snapshot-fail">fail</div>
          <a id="wm-save-snapshot-open" href="#"
	     title="Share via My Web Archive" >
            <span class="iconochive-web"></span>
          </a>
          <a href="https://archive.org/account/login.php"
             title="Sign In"
             id="wm-sign-in"
          >
            <span class="iconochive-person"></span>
          </a>
          <span id="wm-save-snapshot-in-progress" class="iconochive-web"></span>
        	<a href="http://faq.web.archive.org/" title="Get some help using the Wayback Machine" style="top:-6px;"><span class="iconochive-question" style="color:rgb(87,186,244);font-size:160%;"></span></a>
	<a id="wm-tb-close" href="#close" onclick="__wm.h(event);return false;" style="top:-2px;" title="Close the toolbar"><span class="iconochive-remove-circle" style="color:#888888;font-size:240%;"></span></a>
      </div>
      <div id="wm-share">
          <a href="/web/20130307064041/http://web.archive.org/screenshot/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm"
             id="wm-screenshot"
             title="screenshot">
            <span class="wm-icon-screen-shot"></span>
          </a>
          <a href="#"
            id="wm-video"
            title="video">
            <span class="iconochive-movies"></span>
          </a>
	<a id="wm-share-facebook" href="#" data-url="https://web.archive.org/web/20130307064041/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="Share on Facebook" style="margin-right:5px;" target="_blank"><span class="iconochive-facebook" style="color:#3b5998;font-size:160%;"></span></a>
	<a id="wm-share-twitter" href="#" data-url="https://web.archive.org/web/20130307064041/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="Share on Twitter" style="margin-right:5px;" target="_blank"><span class="iconochive-twitter" style="color:#1dcaff;font-size:160%;"></span></a>
      </div>
    </div>
    <table class="c" style="">
      <tbody>
	<tr>
	  <td class="u" colspan="2">
	    <form target="_top" method="get" action="/web/submit" name="wmtb" id="wmtb"><input type="text" name="url" id="wmtbURL" value="http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" onfocus="this.focus();this.select();" /><input type="hidden" name="type" value="replay" /><input type="hidden" name="date" value="20130307064041" /><input type="submit" value="Go" /></form>
	  </td>
	  <td class="n" rowspan="2" style="width:110px;">
	    <table>
	      <tbody>
		<!-- NEXT/PREV MONTH NAV AND MONTH INDICATOR -->
		<tr class="m">
		  <td class="b" nowrap="nowrap"><a href="https://web.archive.org/web/20081121112750/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="21 Nov 2008"><strong>Nov</strong></a></td>
		  <td class="c" id="displayMonthEl" title="You are here: 06:40:41 Mar 07, 2013">MAR</td>
		  <td class="f" nowrap="nowrap"><a href="https://web.archive.org/web/20130503234742/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="03 May 2013"><strong>May</strong></a></td>
		</tr>
		<!-- NEXT/PREV CAPTURE NAV AND DAY OF MONTH INDICATOR -->
		<tr class="d">
		  <td class="b" nowrap="nowrap"><a href="https://web.archive.org/web/20081121112750/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="11:27:50 Nov 21, 2008"><img src="/_static/images/toolbar/wm_tb_prv_on.png" alt="Previous capture" width="14" height="16" border="0" /></a></td>
		  <td class="c" id="displayDayEl" style="width:34px;font-size:24px;white-space:nowrap;" title="You are here: 06:40:41 Mar 07, 2013">07</td>
		  <td class="f" nowrap="nowrap"><a href="https://web.archive.org/web/20130503234742/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="23:47:42 May 03, 2013"><img src="/_static/images/toolbar/wm_tb_nxt_on.png" alt="Next capture" width="14" height="16" border="0" /></a></td>
		</tr>
		<!-- NEXT/PREV YEAR NAV AND YEAR INDICATOR -->
		<tr class="y">
		  <td class="b" nowrap="nowrap"><a href="https://web.archive.org/web/20081121112750/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="21 Nov 2008"><strong>2008</strong></a></td>
		  <td class="c" id="displayYearEl" title="You are here: 06:40:41 Mar 07, 2013">2013</td>
		  <td class="f" nowrap="nowrap"><a href="https://web.archive.org/web/20140520073119/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="20 May 2014"><strong>2014</strong></a></td>
		</tr>
	      </tbody>
	    </table>
	  </td>
	</tr>
	<tr>
	  <td class="s">
	    	    <div id="wm-nav-captures">
	      	      <a class="t" href="/web/20130307064041*/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm" title="See a list of every capture for this URL">38 captures</a>
	      <div class="r" title="Timespan for captures of this URL">23 Apr 2000 - 25 Apr 2016</div>
	      </div>
	  </td>
	  <td class="k">
	    <a href="" id="wm-graph-anchor">
	      <div id="wm-ipp-sparkline" title="Explore captures for this URL" style="position: relative">
		<canvas id="wm-sparkline-canvas" width="650" height="27" border="0"></canvas>
	      </div>
	    </a>
	  </td>
	</tr>
      </tbody>
    </table>
    <div style="position:absolute;bottom:0;right:2px;text-align:right;">
      <a id="wm-expand" class="wm-btn wm-closed" href="#expand" onclick="__wm.ex(event);return false;"><span id="wm-expand-icon" class="iconochive-down-solid"></span> <span style="font-size:80%">About this capture</span></a>
    </div>
  </div>
    <div id="wm-capinfo" style="border-top:1px solid #777;display:none; overflow: hidden">
                    <div id="wm-capinfo-collected-by">
    <div style="background-color:#666;color:#fff;font-weight:bold;text-align:center">COLLECTED BY</div>
    <div style="padding:3px;position:relative" id="wm-collected-by-content">
            <div style="display:inline-block;vertical-align:top;width:50%;">
			<span class="c-logo" style="background-image:url(https://archive.org/services/img/ArchiveIt-Partner-169);"></span>
		Organization: <a style="color:#33f;" href="https://archive.org/details/ArchiveIt-Partner-169" target="_new"><span class="wm-title">Iowa State University</span></a>
		<div style="max-height:75px;overflow:hidden;position:relative;">
	  <div style="position:absolute;top:0;left:0;width:100%;height:75px;background:linear-gradient(to bottom,rgba(255,255,255,0) 0%,rgba(255,255,255,0) 90%,rgba(255,255,255,255) 100%);"></div>
	  Iowa State University<br /><br/>Archive-It Partner Since: Sep, 2007<br/>Organization Type: Colleges & Universities<br/>Organization URL:<a href="http://www.lib.iastate.edu">http://www.lib.iastate.edu</a><br/><br/>The mission of the Iowa State University Library Special Collections Department is to identify, select, preserve, create access to, provide reference assistance for, and promote the use of rare and unique research materials that support major research areas of Iowa State University.<br/>
	</div>
	      </div>
      <div style="display:inline-block;vertical-align:top;width:49%;">
			<span class="c-logo" style="background-image:url(https://archive.org/services/img/ArchiveIt-Collection-1501)"></span>
		<div>Collection: <a style="color:#33f;" href="https://archive.org/details/ArchiveIt-Collection-1501" target="_new"><span class="wm-title">ISU Special Collections Department Manuscript Collections Web Sites</span></a></div>
		<div style="max-height:75px;overflow:hidden;position:relative;">
	  <div style="position:absolute;top:0;left:0;width:100%;height:75px;background:linear-gradient(to bottom,rgba(255,255,255,0) 0%,rgba(255,255,255,0) 90%,rgba(255,255,255,255) 100%);"></div>
	  Collection contains the websites of organizations with collections in the Special Collections Department, Iowa State University Library
	</div>
	      </div>
    </div>
    </div>
    <div id="wm-capinfo-timestamps">
    <div style="background-color:#666;color:#fff;font-weight:bold;text-align:center" title="Timestamps for the elements of this page">TIMESTAMPS</div>
    <div>
      <div id="wm-capresources" style="margin:0 5px 5px 5px;max-height:250px;overflow-y:scroll !important"></div>
      <div id="wm-capresources-loading" style="text-align:left;margin:0 20px 5px 5px;display:none"><img src="/_static/images/loading.gif" alt="loading" /></div>
    </div>
    </div>
  </div></div></div></div><div id="wm-ipp-print">The Wayback Machine - https://web.archive.org/web/20130307064041/http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm</div>
<div id="donato" style="position:relative;width:100%;">
  <div id="donato-base">
    <iframe id="donato-if" src="https://archive.org/includes/donate.php?as_page=1&amp;platform=wb&amp;referer=https%3A//web.archive.org/web/20130307064041/http%3A//www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm"
	    scrolling="no" frameborder="0" style="width:100%; height:100%">
    </iframe>
  </div>
</div><script type="text/javascript">
__wm.bt(650,27,25,2,"web","http://www.amstat.org/publications/jse/secure/v7n3/shaffer.cfm","20130307064041",1996,"/_static/",["/_static/css/banner-styles.css?v=omkqRugM","/_static/css/iconochive.css?v=qtvMKcIJ"], "False");
  __wm.rw(1);
</script>
<!-- END WAYBACK TOOLBAR INSERT -->


<h1>A Novel Method of Proof With an Application to Regression</h1>


<p>Juliet Popper Shaffer<br>
University of California</p>
 
<p>Yung-Pin Chen<br>
Smith College</p>

<p>
<cite>Journal of Statistics Education</cite> v.7, n.3 (1999)

<p> Copyright (c) 1999 by Juliet Popper Shaffer and
Yung-Pin Chen, all rights reserved.  This text may be
freely shared among individuals, but it may not be
republished in any medium without express written consent
from the authors and advance notification of the editor.
</p>

<hr></p>

<strong><p>Key Words:</strong> Best linear unbiased
estimation; Least squares estimation; Unbiased estimation;
Variance estimation.</p>

<h2>Abstract</h2>

<p>A useful way of approaching a statistical problem is to
consider whether the addition of some missing information
would transform the problem into a standard form with a
known solution.  The EM algorithm (<a href="#dempster">Dempster, Laird, and Rubin 1977</a>), for
example, makes use of this approach to simplify
computation.  Occasionally it turns out that knowledge of
the missing values is not necessary to apply the standard
approach.  In such cases the following simple logical
argument shows that any optimality properties of the
standard approach in the full-information situation
generalize  immediately to the approach in the original
limited-information situation: If any better estimate were
available in the limited-information situation, it would
also be available in the full-information situation, which
would contradict the optimality of the original estimator.
This approach then provides a simple proof of optimality,
and often leads directly to a simple derivation of other
properties of the solution.   The approach can be taught to
graduate students and theoretically-inclined
undergraduates.  Its application to the elementary proof of
a result in linear regression, and some extensions, are
described in this paper. The resulting derivations provide
more insight into some equivalences among models as well as
proofs simpler than the standard ones.</p>

<h1>1. Introduction</h1>

<p>
1 Assume the linear regression model <br>

<a name="equation1">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="basic">&#160;</a><img width="118" height="48" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img2.gif" alt="\begin{displaymath}
\bf {y_+} = {X_+} {\mbox{\boldmath$\beta$\unboldmath }_+} 
+ {\mbox{\boldmath$\epsilon$\unboldmath }},
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(1)</td></tr>
</table>
</div>
<br clear="ALL"></a>

where <img width="25" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img3.gif" alt="$\bf {y_+}$">
is an 

<img width="41" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img4.gif" alt="$n \times 1$">
random vector of observations on the dependent variable in
the <i>n</i> experimental units,
<img width="29" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img5.gif" alt="$\bf {X_+}$">
is a fixed, known 

<img width="81" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img6.gif" alt="$n \times (p+1)$">
matrix with all elements of the first column equal to one
and of rank  <nobr><i>p</i> + 1</nobr>, 

<img width="132" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img7.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }_+ = (\beta_0, \ldots, \beta_p)'$">
is a fixed, unknown (<nobr><i>p</i> + 1</nobr>)-vector of
coefficients, and 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">
is a random 

<img width="41" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img4.gif" alt="$n \times 1$">
vector with expected value zero and covariance matrix 

<img width="28" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img9.gif" alt="$\sigma^2 \bf I$">.
 
Under model (1), the best linear unbiased estimator
(<i>BLUE</i>) of the vector 

<img width="26" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img10.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }_+$">
is <br>

<a name="equation2">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="sol">&#160;</a><img width="176" height="48" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img11.gif" alt="\begin{displaymath}
\mathbf{\hat{\mbox{\boldmath$\beta$\unboldmath }}_+} 
= \mathbf{(X_+'X_+)}^{-1} \mathbf{{X_+}'{ y_+}} .
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(2)</td></tr>
</table>
</div>
<br clear="ALL"></a>

<p>2 Let 

<img width="121" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img12.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }= (\beta_1, \ldots, \beta_p)'$">
be the vector of coefficients excluding the constant
additive term. A well-known fact, stated in most regression
textbooks, is that the expression for estimating 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
can be obtained from the inversion of a 

<img width="40" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img14.gif" alt="$p \times p$">
rather than a

<img width="119" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img15.gif" alt="$(p+1) \times (p+1)$">
matrix by expressing <img width="29" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img5.gif" alt="$\bf {X_+}$">
and <img width="25" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img3.gif" alt="$\bf {y_+}$">
in deviation form (i.e., subtracting column  means), and
using an expression of the same form as (2).</p>

<p>3 Let 

<img width="23" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img16.gif" alt="$\overline{y}_+$">
be the mean of the <i>n</i> components of <img width="25" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img3.gif" alt="$\bf {y_+}$">,
and let 

<img width="29" height="36" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img17.gif" alt="$\bf {\overline{X}_+}$">
be the 

<img width="80" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img18.gif" alt="$1 \times (p+1)$">
row vector with elements 

<img width="166" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img19.gif" alt="$\overline {x}_{+,(0)}, 
\overline{x}_{+,(1)}, \ldots,\overline{x}_{+,(p)}$">,
where 

<img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img20.gif" alt="$\overline{x}_{+,(i)}$">
is the mean of the <i>n</i> components of
column <i>i</i> of the matrix <img width="29" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img5.gif" alt="$\bf {X_+}$">.
Let 

<img width="13" height="18" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img21.gif" alt="$\bf\vec {1}$">
be an 

<img width="41" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img4.gif" alt="$n \times 1$">
vector of ones.  Then 

<img width="15" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img22.gif" alt="$\bf\hat{\mbox{\boldmath$\beta$\unboldmath }}$">,
with elements 2 to (<nobr><i>p</i> + 1</nobr>) of 

<img width="26" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img23.gif" alt="$\bf\hat{\mbox{\boldmath$\beta$\unboldmath }}_+$">,
can be expressed as <br>

<a name="equation3">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="devsol">&#160;</a><img width="126" height="47" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img24.gif" alt="\begin{displaymath}
\mathbf {\hat{\mbox{\boldmath$\beta$\unboldmath }} = (X'X)}^{-1} \bf {X' y},
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(3)</td></tr>
</table>
</div>
<br clear="ALL"></a>
where <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">
is the 

<img width="41" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img26.gif" alt="$n \times p$">
matrix consisting of columns 2 to (<nobr><i>p</i> +
1</nobr>) of  

<img width="97" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img27.gif" alt="$\bf ( {X_+} - \vec{1} \, \overline{X}_+)$">
(the first column of  

<img width="97" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img27.gif" alt="$\bf ( {X_+} - \vec{1} \, \overline{X}_+)$">
is identically zero and is dropped) and  

<img width="91" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img28.gif" alt="$\bf y = (\bf {y_+} - \vec{1}$">


<img width="29" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img29.gif" alt="$\overline{y}_+)$">.
The proof of this result is not immediately obvious because
the covariance matrix of 
<img width="14" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img30.gif" alt="$\bf y$">,
given <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">,
is no longer 

<img width="28" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img9.gif" alt="$\sigma^2 \bf I$">
but is <br>

<a name="equation4">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="covar">&#160;</a><img width="147" height="48" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img31.gif" alt="\begin{displaymath}
\bf {\Sigma_y} = \sigma^2 [{\bf {I} - \mbox{$(1/n)$ } \bf J}]
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(4)</td></tr>
</table>
</div>
<br clear="ALL"></a>
where <img width="14" height="15" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img32.gif" alt="$\bf J$">
is an 

<img width="43" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img33.gif" alt="$n \times n$">
matrix with all elements equal to 1. <a href="#draper">Draper and Smith (1998, pp. 27-28)</a> and
<a href="#daniel">Daniel and Wood (1980, pp. 13-14)</a>
state the result without proof. <a href="#sen">Sen and
Srivastava (1990, pp. 42 and 146)</a> ask for the proof in
a problem, and suggest using a generalized inverse (since
the covariance matrix (4) is singular).  <a href="#arnold">Arnold (1981)</a>, <a href="#graybill">Graybill (1976)</a>, <a href="#searle">Searle (1971)</a>, and <a href="#seber">Seber (1977)</a> have relatively long proofs
involving partitioning of matrices.

<p>4 This paper presents a proof that involves only
elementary facts that are usually presented in a first
introduction to  regression.  The method of proof involves
consideration of missing information that, if known, would
put the equation to be solved into a standard regression
form.</p> <p>

<a name="section2">
<h1>2. Proof of the Equivalence of Raw Form and Deviation
Form Solutions </h1></a>

<p>5 Under Model <a href="#equation1">(1)</a>, noting that
<br>

<a name="equation5">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="means">&#160;</a><img width="157" height="48" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img34.gif" alt="\begin{displaymath}
\bf\vec{1} \,\mbox{$\overline{y}_+$ }
=\vec{1} \,(\overline{X}_+ \mbox{\boldmath$\beta$\unboldmath }_+ +
\overline{\epsilon}),
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(5)</td></tr>
</table>
</div>
<br clear="ALL"></a>
where 

<img width="11" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img35.gif" alt="$\overline{\epsilon}$">
is the mean of the <i>n</i> components of 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">,
and subtracting (5) from (1) yields
<br>

<a name="equation6">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="deveq">&#160;</a><img width="124" height="46" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img36.gif" alt="\begin{displaymath}
\bf y = X \mbox{\boldmath$\beta$\unboldmath }
+ \mbox{\boldmath$\epsilon$\unboldmath }- \vec{1}\, \overline{\epsilon},
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(6)</td></tr>
</table>
</div>
<br clear="ALL"></a>
where <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">
is the 

<img width="41" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img26.gif" alt="$n \times p$">
matrix defined below <a href="#equation3">Equation (3)</a>.  Suppose 
<img width="11" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img35.gif" alt="$\overline{\epsilon}$">
were known.  Adding 

<img width="23" height="19" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img37.gif" alt="$\bf\vec{1}\, \overline{\epsilon}$">
to both sides of (6) yields the equation
<br>

<a name="equation7">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="barform">&#160;</a><img width="94" height="46" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img38.gif" alt="\begin{displaymath}
\bf y^* = X \mbox{\boldmath$\beta$\unboldmath }
+ \mbox{\boldmath$\epsilon$\unboldmath },
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(7)</td></tr>
</table>
</div>
<br clear="ALL"></a>
where 

<img width="90" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img39.gif" alt="$\bf y^* = y + \vec{1}\, \overline{\epsilon}$">.
Note that 

<img width="92" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img40.gif" alt="$\bf E(y^*) = X \mbox{\boldmath$\beta$\unboldmath }$">
and

<img width="79" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img41.gif" alt="$\bf {\Sigma_{y^*}} = \sigma^2 \bf I$">,
so (7) is in the form (1), but with <img width="25" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img3.gif" alt="$\bf {y_+}$">
and 
<img width="29" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img5.gif" alt="$\bf {X_+}$">
replaced by <img width="22" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img56.gif" alt="$\bf {y^*}$">
and <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">,
the latter in deviation form. Thus, the <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
is <br>

<a name="equation8">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap>
<a name="newdevsol">&#160;</a><img width="408" height="47" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img43.gif" alt="\begin{displaymath}
 \tilde{\mbox{\boldmath$\beta$\unboldmath }} 
= \mathbf {(X'X)}^{-1}  \mathbf{X' y^*}
= \mathbf{(X'X)} ^{-1} \mathbf{X'(y+ \vec{1} \, \overline{\epsilon}}) 
= \mathbf{(X'X)} ^{-1} \mathbf{X' y}.
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(8)</td></tr>
</table>
</div>
<br clear="ALL"></a>
The last equality follows because, although 

<img width="11" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img35.gif" alt="$\overline{\epsilon}$">,
which appears in (8), is unknown, each element <i>i</i> of
the vector

<img width="53" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img44.gif" alt="$\bf X' (\vec{1} \, \overline{\epsilon})$">
is in the form 

<img width="108" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img45.gif" alt="$\overline{\epsilon}\, ({\Sigma_{i=1}^n} {x_{ij}}) = 0$">,

<img width="84" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img46.gif" alt="$j = 1, \ldots, p$">,
since <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">
is in deviation form.  Then 

<img width="15" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img47.gif" alt="$\bf\tilde{\mbox{\boldmath$\beta$\unboldmath }}$">
is the <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">,
as is 

<img width="26" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img23.gif" alt="$\bf\hat{\mbox{\boldmath$\beta$\unboldmath }}_+$">
omitting the first element.  Therefore, 

<img width="26" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img23.gif" alt="$\bf\hat{\mbox{\boldmath$\beta$\unboldmath }}_+$">,
without the intercept element, and 

<img width="15" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img47.gif" alt="$\bf\tilde{\mbox{\boldmath$\beta$\unboldmath }}$">
must be equivalent.

<p>

<h1>3. Extensions</h1>

<p>
6 Note that, instead of adding 

<img width="35" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img48.gif" alt="$ (\bf {\vec{1}} \, \overline{\epsilon})$">
to both sides of <a href="#equation6">(6)</a> in <a href="#section2">Section 2</a>, the realization of any
random variable independent of 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">
with mean zero and variance 

<img width="39" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img49.gif" alt="$\sigma^2/n $">
could be added to each observation, and the proof would
proceed in the same way.  By combining the method of
Section 2 with the addition of an external variable
independent of


<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">,
a further equivalence can be demonstrated.</p>

<p><i>Theorem</i>: 
Consider a model of the form <a href="#equation1">(1)</a>
but in which the covariance matrix of 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">
is <br>

<a name="equation9">
<div align="CENTER">
<table width="100%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="newcov">&#160;</a><img width="323" height="47" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img50.gif" alt="\begin{displaymath}
 \mathbf {\Sigma_{\mbox{\boldmath$\epsilon$\unboldmath }}} 
= \sigma^2 {[(1-\rho)  \bf {I} +
\rho J]}, \; \; {\mbox{${-1/(n-1)}\leq \rho \leq 1$ }}.
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(9)</td></tr>
</table>
</div>
<br clear="ALL"></a>
The <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
in the model (1) but with the covariance matrix of 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">
given by Equation (9) is the same as the <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
in the model (1) with the covariance matrix of 

<img width="57" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img51.gif" alt="${\mbox{\boldmath$\epsilon$\unboldmath }} = \sigma^2 \bf I$">
(note that

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
is   

<img width="26" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img10.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }_+$">
without the intercept term).  Furthermore, the  covariance
matrix of the <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
with error covariance
matrix (9) is <img width="52" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img52.gif" alt="$(1 -\rho)$">
times as great as the covariance matrix of the <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
with error covariance matrix  

<img width="28" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img9.gif" alt="$\sigma^2 \bf I$">.</p>

<p><i>Proof</i>:
Three cases will be considered separately.

<ol type="i">
<p><li>
<img width="47" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img53.gif" alt="$\rho \,=\,0$">.
In this case, the model reduces to <a href="#equation1">(1)</a> with error
covariance matrix 

<img width="28" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img9.gif" alt="$\sigma^2 \bf I$">,
so no proof is needed.</p>

<p><li>
<img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img54.gif" alt="$ \rho < 0$">.
As in <a href="#section2">Section 2</a>, convert the model
(1) into the form  <a href="#equation7">(7)</a> by
subtracting the expression for

<img width="34" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img55.gif" alt="$\mathbf{\vec{1}} \overline{y}_+$">
from (1) and adding 

<img width="23" height="19" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img37.gif" alt="$\bf\vec{1}\, \overline{\epsilon}$">
to both sides.  The covariance matrix of <img width="22" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img56.gif" alt="$\bf {y^*}$">
is unchanged from that of <img width="25" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img3.gif" alt="$\bf {y_+}$">
by this transformation; i.e., it is given by <a href="#equation9">(9)</a>. Now add a
random vector 

<img width="24" height="19" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img57.gif" alt="$\bf {\vec{1}} \,\delta$">
to both sides of (7), where <img width="12" height="15" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/delta.gif" alt="$ \delta$">
is the realization of a real-valued random variable
independent of 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">
and with expected value zero and variance 

<img width="38" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img59.gif" alt="$\sigma^2\vert\rho\vert$">.
The equation (7) becomes <br>

<a name="equation10">
<div align="CENTER">
<table width="90%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="negrhoeq">&#160;</a><img width="169" height="46" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img60.gif" alt="\begin{displaymath}
 \bf {{y^*} + {\vec {1}}}\,  \delta =
\bf {{X} {\mbox{\boldmath$\beta$\unboldmath }} 
+  \mbox{\boldmath$\epsilon$\unboldmath }+ \vec{1}}\,  \delta
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(10)</td></tr>
</table>
</div>
<br clear="ALL"></a>
or <br>

<a name="equation11">
<div align="CENTER">
<table width="90%" align="CENTER">
<tr valign="MIDDLE"><td align="CENTER" nowrap><a name="znegrho">&#160;</a><img width="84" height="46" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img61.gif" alt="\begin{displaymath}
\bf {z} = \bf {X} {\mbox{\boldmath$\beta$\unboldmath }} 
+ \mbox{\boldmath$\eta$\unboldmath }
\end{displaymath}"></td>
<td width="5%" align="RIGHT">
(11)</td></tr>
</table>
</div>
<br clear="ALL"></a>
where 

<img width="90" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img62.gif" alt="$\bf {z} = \bf {{y^*}} + \bf {\vec{1}} \, \delta$">
and

<img width="82" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img63.gif" alt="$ \mbox{\boldmath$\eta$\unboldmath }
= \mbox{\boldmath$\epsilon$\unboldmath }+ \bf {\vec{1}}\, \delta$">.
The covariance matrix of 

<img width="14" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldeta.gif" alt="$\mbox{\boldmath$\eta$\unboldmath }$">
is 

<img width="120" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img65.gif" alt="$\sigma^2 (1-\rho) \bf I =
\rm\tau^2 \bf I$">,
where 

<img width="106" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img66.gif" alt="$\tau^2 = (1 - \rho) \sigma^2$">,
and therefore Model (11) is in the same form as Model (7),
with a covariance matrix 

<img width="52" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img52.gif" alt="$(1 -\rho)$">
times as large, so the theorem follows from the previous
one.  A proof along these lines was used in <a href="#shaffer81">Shaffer (1981, p. 609)</a>.</p>

<p><li>
<img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img67.gif" alt="$ \rho > 0$">.
The proof extends to the case <img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img67.gif" alt="$ \rho > 0$">
by first converting the model to <a href="#equation7">(7)</a> with <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">
in deviation form as in (ii).  Now express 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">
as 

<img width="53" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img68.gif" alt="$ \mbox{\boldmath$\eta$\unboldmath }+ \bf\vec{1}\, \delta$">,
where 

<img width="14" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldeta.gif" alt="$\mbox{\boldmath$\eta$\unboldmath }$">
is a random 

<img width="41" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img4.gif" alt="$n \times 1$">
vector with mean zero and covariance matrix

<img width="76" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img69.gif" alt="$\sigma^2 (1-\rho) \bf I$">,
and <img width="12" height="15" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/delta.gif" alt="$ \delta$">
is a real-valued random variable with mean zero and variance 

<img width="29" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img70.gif" alt="$\sigma^2\rho$">.
Subtract 

<img width="24" height="19" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img57.gif" alt="$\bf {\vec{1}} \,\delta$">
from both sides of (7), so that the resulting model is in
the same form as Model (7), with a covariance matrix <img width="52" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img52.gif" alt="$(1 -\rho)$">
times as large, as in (ii), but now with

<img width="87" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img71.gif" alt="$\bf {z} = \bf {y^*} - \vec{1} \delta$">.
The proof proceeds as in (ii).</p>
</ol>

<p>
7 The proof for <img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img67.gif" alt="$ \rho > 0$">
 requires a further comment.  Up to now, there has been no
reference to the distribution of the errors, except for
expected values and variances. As is well known, the
results above are distribution-free, requiring only that
<img width="21" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img72.gif" alt="$\sigma^2$">
be finite.  However, the proof above for <img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img67.gif" alt="$ \rho > 0$">,
in which a random vector is expressed as the sum of two
others, requires some distributional assumption, since not
all random vectors can be expressed in that form.</p>

<p>8 Assume two models A and B with the same regression
coefficients but different error covariance matrices. 
Because the <i>BLUE</i>, given any model, has a fixed form,
depending only on the covariance matrix of the errors and
not on other features of the error distribution (of course
with means of errors equal to zero), it follows that if A
and B (with the specified error covariance matrices above)
have the same <i>BLUE</i>s under any error distribution,
they have the same <i>BLUE</i>s for all error
distributions.  Therefore, it can be assumed, without loss
of generality, that the error distributions are normal.  In
that case, the proof of the theorem for
<img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img67.gif" alt="$ \rho > 0$">
can be carried out, since a normal random vector with the
given covariance matrix can be decomposed as required in the proof.</p>

<p> 9 Note that another proof, in the same spirit, that
combines negative and positive values of <img width="13" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/rho.gif" alt="$\rho$">
can be obtained by transforming the model into the
deviation form <a href="#equation6">(6)</a>, and then
adding the realization of a single independent random
variable with variance 

<img width="87" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img74.gif" alt="$\sigma^2 (1-\rho)/n$">
to each observation. The proof using this alternative
approach appears to be more compact but involves somewhat
more matrix manipulation than the previous one. Both proofs
start with the deviation form (6).  In order to determine
the variance of the single independent variable value to be
added to each observation using this alternative proof, it
is necessary to derive the covariance matrix of (<img width="47" height="37" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img75.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }
- \bf {\vec{1}} \bar{\epsilon}$">),  
which requires a fair amount of calculation because of the 
nonzero covariances in <a href="#equation9">(9)</a>.  In
the original proof given,  by starting with (6) and adding
(<img width="20" height="19" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img76.gif" alt="$\bf {\vec{1}} \bar{\epsilon}$">)
to both sides, it is immediately clear that the equation is
in the form <a href="#equation7">(7)</a> with the
covariance matrix unchanged from the original form (9). 
The single further step, required in both proofs,  involves
adding (or subtracting) the realization of a random
variable, independent of 

<img width="12" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldepsilon.gif" alt="$\mbox{\boldmath$\epsilon$\unboldmath }$">,
to each observation. The only knowledge needed for this
latter step is that the variance of that random variable is
added to every term in the covariance matrix; this is easy
to show. However, the alternative proof, although somewhat
more complex than the first one given, is nonetheless
simpler than proofs presently available in the literature.</p>

<p> 10 <a href="#mcelroy">McElroy (1967)</a> proved that
the error covariance matrix (9) is a necessary and
sufficient condition for <a href="#equation2">(2)</a> to be the <i>BLUE</i> of 

<img width="26" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img10.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }_+$">
in Model <a href="#equation1">(1)</a>, for

<img width="141" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img77.gif" alt="$-1/(n-1) < \rho < 1$">.
McElroy's result is more general than the result in this
theorem in that it includes the estimate of <img width="20" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img78.gif" alt="$\beta_0$">
and includes necessity as well as sufficiency of (9). On
the other hand, the result in this theorem is more general
than McElroy's result in that the singular matrices
resulting when

<img width="111" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img79.gif" alt="$\rho = -1/(n-1)$">
and when <img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img80.gif" alt="$\rho = 1$">
are included in the range of <img width="13" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/rho.gif" alt="$\rho$">.</p>

<p>
11 An interesting insight follows from considering the case <img width="42" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img80.gif" alt="$\rho = 1$">.
In this case, there is (with probability one) a single
realization <img width="11" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/epsilon.gif" alt="$\epsilon$">
of a random variable added to the expected value for each
observation.  Then, in the form <a href="#equation6">(6)</a>, each element of <img width="14" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img30.gif" alt="$\bf y$">
is exactly equal to its expected value,
so the covariance matrix of <img width="14" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img30.gif" alt="$\bf y$">
is the null matrix, and

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
can be calculated exactly.</p>



<h1>4. Conclusion</h1>

<p>12 The development in <a href="#section2">Section 2</a>
provides a simple proof that estimators of the coefficient
vector in a standard linear model, excluding the intercept
term, can be obtained by expressing the sample values of
the predictors and predicted variable in deviation form and
using the standard equation for the estimator of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
in a model without an intercept.  From a geometric point of
view, note that the regression plane goes through the
point (<img width="151" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img82.gif" alt="$ \overline{x}_{+,(1)}, \ldots,\overline{x}_{+,(p)},
\overline{y}_+)$">,
and centering shifts the plane to go through the origin but
doesn't change the slopes.  (Of course the solution in this
paper is for a model with an intercept, and should not be
confused with the solution for a model that assumes an
intercept of zero, for which the estimators and their
properties are different.)  The proof proceeds by noting
that the addition of an unknown value 

<img width="23" height="31" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img83.gif" alt="$(\overline{\epsilon})$">
would put the relevant expressions into standard form.  The
same approach, with the addition of an external random
vector, leads to a simple proof that the <i>BLUE</i> of 

<img width="15" height="29" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/boldbeta.gif" alt="$\mbox{\boldmath$\beta$\unboldmath }$">
when the error covariance matrix is of the form 

<img width="122" height="33" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img84.gif" alt="$\sigma^2 [(1-\rho) \bf I + \rho \bf J]$">
is the same as when it is of the standard form 

<img width="28" height="17" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img9.gif" alt="$\sigma^2 \bf I$">,
and yields a simple expression for the comparative
variances of the estimators. It follows also from the proof
that the results hold even if the covariance matrix of <img width="25" height="28" align="MIDDLE" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img3.gif" alt="$\bf {y_+}$">
is singular. Neither extensive matrix manipulation nor
knowledge of generalized inverses is necessary.  The
results generalize under appropriate conditions to the
correlation model (<a href="#arnold">Arnold 1981</a>, <a href="#shaffer91">Shaffer 1991</a>), in which the elements
of <img width="18" height="14" align="BOTTOM" border="0" src="/web/20130307064041im_/http://www.amstat.org/publications/jse/secure/v7n3/shaffer/img25.gif" alt="$\bf X$">
are realizations of random variables.</p>

<h2>Acknowledgments</h2>

<p>We would like to thank Katherine Halvorsen for
her valuable comments which helped to improve the
presentation of this paper.</p>

<p><hr></p>

<h1>References</h1>


<p><a name="arnold"> Arnold, S. F. (1981)</a>, <cite>The
Theory of Linear Models and Multivariate Analysis</cite>, 
New York: Wiley-Interscience. </p>

<p><a name="daniel"> Daniel, C. and Wood, F. S. (1980)</a>,
<cite>Fitting Equations to Data: Computer Analysis of
Multifactor Data for Scientists and Engineers</cite> (2nd
ed.), New York: Wiley-Interscience. </p>

<p><a name="dempster"> Dempster, A. P., Laird, N. M., and
Rubin, D. B. (1977)</a>,  "Maximum Likelihood From
Incomplete Data Via the EM Algorithm," <cite>Journal of the
Royal Statistical Society</cite>, Ser. B, 39, 1-22. </p>

<p><a name="draper"> Draper, N. R., and Smith, H.
(1998)</a>, <cite>Applied Regression Analysis</cite>  (3rd
ed.), New York: Wiley. </p>

<p><a name="graybill"> Graybill, F. A. (1976)</a>,
<cite>Theory and Application of the Linear Model</cite>, 
North Scituate, MA: Duxbury Press. </p>

<p><a name="mcelroy"> McElroy, F. W. (1967)</a>, "A
Necessary and Sufficient Condition That Ordinary Least
Squares Estimators Be Best Linear Unbiased," <cite>Journal
of the American Statistical Association</cite>, 62,
1302-1304. </p>

<p><a name="searle"> Searle, S. R. (1971)</a>. <cite>Linear
Models</cite>,  New York: Wiley. </p>

<p><a name="seber"> Seber, G. A. F. (1977)</a>,
<cite>Linear Regression Analysis</cite>, New York: Wiley.
</p>

<p><a name="sen"> Sen, A., and Srivastava, M. (1990)</a>,
<cite>Regression Analysis: Theory, Methods, and
Applications</cite>, New York: Springer-Verlag. </p>

<p><a name="shaffer81"> Shaffer, J. P. (1981)</a>, "The
Analysis of Variance Mixed Model With Allocated
Observations: Application to Repeated Measurement Designs,"
<cite>Journal of the American Statistical
Association</cite>, 76, 607-611. </p>

<p><a name="shaffer91"> ----- (1991)</a>, "The Gauss-Markov
Theorem and Random Regressors," <cite>The American
Statistician</cite>, 45, 269-273. </p>

<hr>

<p>
Juliet Popper Shaffer<br>
University of California<br>
Department of Statistics<br>
367 Evans Hall #3860<br>
Berkeley, CA 94720-3860<br>
<address> shaffer@stat.berkeley.edu </address></p>

<p>
Yung-Pin Chen<br>
Department of Mathematics<br>
Smith College<br>
Northampton, MA 01063<br>
<address>ypchen@neal.smith.edu</address></p>

<hr>

<p align="center"><font face="Arial"><small><a href="/web/20130307064041/http://www.amstat.org/publications/jse/index.html">JSE Homepage</a> | <a href="https://web.archive.org/web/20130307064041/https://www.amstat.org/publications/jse/JSEForm.htm">Subscription
Information</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/contents.cfm">Current Issue</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/toc.html">JSE Archive (1993-1998)</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/archive.htm">Data Archive</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/jindex.html">Index</a> | Search
JSE | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/information.html">JSE Information Service</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/board.html">Editorial Board</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/jse/ifa.html">Information for Authors</a> | <a href="https://web.archive.org/web/20130307064041/mailto:journals@amstat.org">Contact JSE</a> | <a href="/web/20130307064041/http://www.amstat.org/publications/">ASA Publications</a></small></font></p>

</body>
</html>

<!--
     FILE ARCHIVED ON 06:40:41 Mar 07, 2013 AND RETRIEVED FROM THE
     INTERNET ARCHIVE ON 13:06:11 Oct 27, 2021.
     JAVASCRIPT APPENDED BY WAYBACK MACHINE, COPYRIGHT INTERNET ARCHIVE.

     ALL OTHER CONTENT MAY ALSO BE PROTECTED BY COPYRIGHT (17 U.S.C.
     SECTION 108(a)(3)).
-->
<!--
playback timings (ms):
  captures_list: 164.961
  exclusion.robots: 0.265
  exclusion.robots.policy: 0.255
  RedisCDXSource: 26.591
  esindex: 0.011
  LoadShardBlock: 115.337 (3)
  PetaboxLoader3.datanode: 113.277 (4)
  CDXLines.iter: 19.545 (3)
  load_resource: 67.562
  PetaboxLoader3.resolve: 32.794
-->